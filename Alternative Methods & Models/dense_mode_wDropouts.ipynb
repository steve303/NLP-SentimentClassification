{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"dense_mode_wDropouts.ipynb","provenance":[{"file_id":"1NuDriAgatWwGmf85aPh9a9yESWK9-xna","timestamp":1607379642087},{"file_id":"1-S4Ug8mMaHrA1gNprzMcvr1va0pUfrT0","timestamp":1607374928738},{"file_id":"1UQt8sZxG5_Qlnft28OG3htNrGOYj7Z4a","timestamp":1607367173838}],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.3"}},"cells":[{"cell_type":"code","metadata":{"id":"HIe_k81Z-4Hx"},"source":["#run if using colab\n","#uninstall if problem during bert tokenization then reinstall below\n","!pip uninstall bert-for-tf2"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"XtCJNCo-dFXn"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"CUj3of3JE5ua"},"source":["!pip install bert-for-tf2"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"0_Uqg5HN_LUM"},"source":["!pip install sentencepiece"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"8E0wwjuJ9Rwr"},"source":["!pip install emoji --upgrade"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"No_VGWsT9YZx"},"source":["#cd to folder which contain required external files, TEXT_MODEL.py and text_preprocessing.py\n","%cd /content/drive/MyDrive/Colab\\ Notebooks/cs410/CourseProject "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"JTVQh4lf6VTe"},"source":["import tensorflow as tf \n","import tensorflow_hub as hub \n","from tensorflow.keras import layers\n","import bert\n","import numpy as np \n","import pandas as pd \n","import json\n","import re\n","import random\n","import math\n","#from TEXT_MODEL import TEXT_MODEL\n","from TEXT_PREPROCESSING_01 import preprocess_text"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lKLcMTfG-fZd","executionInfo":{"status":"ok","timestamp":1607372109291,"user_tz":420,"elapsed":3646,"user":{"displayName":"Steven Su","photoUrl":"","userId":"12872522105664994411"}},"outputId":"fdb19889-68ec-460c-c248-0d4dc7479b52"},"source":["\n","# LOADING DATA\n","categorized_tweets = pd.read_json('./data/train.jsonl', lines = True)\n","categorized_tweets.isnull().values.any()\n","print(categorized_tweets)\n","\n","# PREPROCESSING DATA\n","tweets = []\n","data = list(categorized_tweets[\"response\"])\n","print(data[0])\n","for d in data:\n","    tweets.append(preprocess_text(d))\n","\n","y = categorized_tweets[\"label\"]\n","y = np.array(list(map(lambda x: 1 if x==\"SARCASM\" else 0, y)))\n","\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["            label  ...                                            context\n","0         SARCASM  ...  [A minor child deserves privacy and should be ...\n","1         SARCASM  ...  [@USER @USER Why is he a loser ? He's just a P...\n","2         SARCASM  ...  [Donald J . Trump is guilty as charged . The e...\n","3         SARCASM  ...  [Jamie Raskin tanked Doug Collins . Collins lo...\n","4         SARCASM  ...  [Man ... y â€™ all gone â€œ both sides â€ the apoca...\n","...           ...  ...                                                ...\n","4995  NOT_SARCASM  ...  [@USER Apologies for the inconvenience you fac...\n","4996  NOT_SARCASM  ...  [@USER ðŸ¤” idk tho , I think I â€™ m #hungry . But...\n","4997  NOT_SARCASM  ...  [@USER @USER @USER Peace to you , and two coun...\n","4998  NOT_SARCASM  ...  [Bernie Sanders told Elizabeth Warren in priva...\n","4999  NOT_SARCASM  ...  [PDP PROTEST BRAINSTORMING SESSION Deji : We n...\n","\n","[5000 rows x 3 columns]\n","@USER @USER @USER I don't get this .. obviously you do care or you would've moved right along .. instead you decided to care and troll her ..\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MmdV7Bl8HaY9","executionInfo":{"status":"ok","timestamp":1607372192566,"user_tz":420,"elapsed":77771,"user":{"displayName":"Steven Su","photoUrl":"","userId":"12872522105664994411"}},"outputId":"07b9d2cc-96b9-463d-c55a-d8a6dbba1f21"},"source":["# TOKENIZING DATA\n","\n","BertTokenizer = bert.bert_tokenization.FullTokenizer\n","\n","bert_layer = hub.KerasLayer(\"https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/3\", trainable=False)\n","vocabulary_file = bert_layer.resolved_object.vocab_file.asset_path.numpy()\n","to_lower_case = bert_layer.resolved_object.do_lower_case.numpy()\n","tokenizer = BertTokenizer(vocabulary_file, to_lower_case)\n","\n","def tokenize_tweets(data):\n","    return tokenizer.convert_tokens_to_ids(tokenizer.tokenize(data))\n","  ##vectorized tweet\n","tokenized_tweets = [tokenize_tweets(tweet) for tweet in tweets]  \n","\n","# tokenized example\n","print(tweets[9])\n","print(tokenizer.tokenize(tweets[9]))\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["@USER @USER @USER responds to facts by tossing out frantic insults , then accuses others of being \" triggered by facts \" :rolling_on_the_floor_laughing: :face_with_tears_of_joy: :rolling_on_the_floor_laughing:\n","['@', 'user', '@', 'user', '@', 'user', 'responds', 'to', 'facts', 'by', 'tossing', 'out', 'frantic', 'insults', ',', 'then', 'accuse', '##s', 'others', 'of', 'being', '\"', 'triggered', 'by', 'facts', '\"', ':', 'rolling', '_', 'on', '_', 'the', '_', 'floor', '_', 'laughing', ':', ':', 'face', '_', 'with', '_', 'tears', '_', 'of', '_', 'joy', ':', ':', 'rolling', '_', 'on', '_', 'the', '_', 'floor', '_', 'laughing', ':']\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xZG8FUEA6kFr","executionInfo":{"status":"ok","timestamp":1607372192567,"user_tz":420,"elapsed":72368,"user":{"displayName":"Steven Su","photoUrl":"","userId":"12872522105664994411"}},"outputId":"0b3d72ae-8a00-413c-c090-884866189667"},"source":["#find the longest tweet in order to pad shorter tweets w zeros\n","maxlength = 0\n","for alist in tokenized_tweets:\n","    if len(alist) > maxlength:\n","        maxlength = len(alist)\n","        \n","maxlength   "],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["120"]},"metadata":{"tags":[]},"execution_count":43}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CseeOudC9mon","executionInfo":{"status":"ok","timestamp":1607372192568,"user_tz":420,"elapsed":70284,"user":{"displayName":"Steven Su","photoUrl":"","userId":"12872522105664994411"}},"outputId":"a7f36687-1883-4ff9-8b4c-8f555345c731"},"source":["#pad the input vector, tweets, so all observations have the same length\n","from keras.preprocessing.sequence import pad_sequences\n","tokenized_tweets_padded = pad_sequences(tokenized_tweets, maxlen=maxlength, padding = 'post')\n","tokenized_tweets_padded[0]"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([ 1030,  5310,  1030,  5310,  1030,  5310,  1045,  2123,  1005,\n","        1056,  2131,  2023,  1012,  1012,  5525,  2017,  2079,  2729,\n","        2030,  2017,  2052,  1005,  2310,  2333,  2157,  2247,  1012,\n","        1012,  2612,  2017,  2787,  2000,  2729,  1998, 18792,  2014,\n","        1012,  1012,     0,     0,     0,     0,     0,     0,     0,\n","           0,     0,     0,     0,     0,     0,     0,     0,     0,\n","           0,     0,     0,     0,     0,     0,     0,     0,     0,\n","           0,     0,     0,     0,     0,     0,     0,     0,     0,\n","           0,     0,     0,     0,     0,     0,     0,     0,     0,\n","           0,     0,     0,     0,     0,     0,     0,     0,     0,\n","           0,     0,     0,     0,     0,     0,     0,     0,     0,\n","           0,     0,     0,     0,     0,     0,     0,     0,     0,\n","           0,     0,     0,     0,     0,     0,     0,     0,     0,\n","           0,     0,     0], dtype=int32)"]},"metadata":{"tags":[]},"execution_count":44}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"armOGe1e-hiB","executionInfo":{"status":"ok","timestamp":1607372192569,"user_tz":420,"elapsed":69251,"user":{"displayName":"Steven Su","photoUrl":"","userId":"12872522105664994411"}},"outputId":"a108bcd1-faa0-4c36-8450-3b72c224f5d4"},"source":["type(tokenized_tweets_padded)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["numpy.ndarray"]},"metadata":{"tags":[]},"execution_count":45}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LGrPcsEcHo1J","executionInfo":{"status":"ok","timestamp":1607372192570,"user_tz":420,"elapsed":68489,"user":{"displayName":"Steven Su","photoUrl":"","userId":"12872522105664994411"}},"outputId":"eb657c27-7318-436c-fb42-320fdc76fc92"},"source":["df_x = pd.DataFrame(tokenized_tweets_padded)\n","df_x.shape"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(5000, 120)"]},"metadata":{"tags":[]},"execution_count":46}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":253},"id":"nOjcaVE9KCt1","executionInfo":{"status":"ok","timestamp":1607372192571,"user_tz":420,"elapsed":66118,"user":{"displayName":"Steven Su","photoUrl":"","userId":"12872522105664994411"}},"outputId":"3356fd96-493b-496a-b5ad-779b33c8e210"},"source":["df_x.head()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>0</th>\n","      <th>1</th>\n","      <th>2</th>\n","      <th>3</th>\n","      <th>4</th>\n","      <th>5</th>\n","      <th>6</th>\n","      <th>7</th>\n","      <th>8</th>\n","      <th>9</th>\n","      <th>10</th>\n","      <th>11</th>\n","      <th>12</th>\n","      <th>13</th>\n","      <th>14</th>\n","      <th>15</th>\n","      <th>16</th>\n","      <th>17</th>\n","      <th>18</th>\n","      <th>19</th>\n","      <th>20</th>\n","      <th>21</th>\n","      <th>22</th>\n","      <th>23</th>\n","      <th>24</th>\n","      <th>25</th>\n","      <th>26</th>\n","      <th>27</th>\n","      <th>28</th>\n","      <th>29</th>\n","      <th>30</th>\n","      <th>31</th>\n","      <th>32</th>\n","      <th>33</th>\n","      <th>34</th>\n","      <th>35</th>\n","      <th>36</th>\n","      <th>37</th>\n","      <th>38</th>\n","      <th>39</th>\n","      <th>...</th>\n","      <th>80</th>\n","      <th>81</th>\n","      <th>82</th>\n","      <th>83</th>\n","      <th>84</th>\n","      <th>85</th>\n","      <th>86</th>\n","      <th>87</th>\n","      <th>88</th>\n","      <th>89</th>\n","      <th>90</th>\n","      <th>91</th>\n","      <th>92</th>\n","      <th>93</th>\n","      <th>94</th>\n","      <th>95</th>\n","      <th>96</th>\n","      <th>97</th>\n","      <th>98</th>\n","      <th>99</th>\n","      <th>100</th>\n","      <th>101</th>\n","      <th>102</th>\n","      <th>103</th>\n","      <th>104</th>\n","      <th>105</th>\n","      <th>106</th>\n","      <th>107</th>\n","      <th>108</th>\n","      <th>109</th>\n","      <th>110</th>\n","      <th>111</th>\n","      <th>112</th>\n","      <th>113</th>\n","      <th>114</th>\n","      <th>115</th>\n","      <th>116</th>\n","      <th>117</th>\n","      <th>118</th>\n","      <th>119</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1030</td>\n","      <td>5310</td>\n","      <td>1030</td>\n","      <td>5310</td>\n","      <td>1030</td>\n","      <td>5310</td>\n","      <td>1045</td>\n","      <td>2123</td>\n","      <td>1005</td>\n","      <td>1056</td>\n","      <td>2131</td>\n","      <td>2023</td>\n","      <td>1012</td>\n","      <td>1012</td>\n","      <td>5525</td>\n","      <td>2017</td>\n","      <td>2079</td>\n","      <td>2729</td>\n","      <td>2030</td>\n","      <td>2017</td>\n","      <td>2052</td>\n","      <td>1005</td>\n","      <td>2310</td>\n","      <td>2333</td>\n","      <td>2157</td>\n","      <td>2247</td>\n","      <td>1012</td>\n","      <td>1012</td>\n","      <td>2612</td>\n","      <td>2017</td>\n","      <td>2787</td>\n","      <td>2000</td>\n","      <td>2729</td>\n","      <td>1998</td>\n","      <td>18792</td>\n","      <td>2014</td>\n","      <td>1012</td>\n","      <td>1012</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1030</td>\n","      <td>5310</td>\n","      <td>1030</td>\n","      <td>5310</td>\n","      <td>2667</td>\n","      <td>2000</td>\n","      <td>6186</td>\n","      <td>2055</td>\n","      <td>1012</td>\n","      <td>3331</td>\n","      <td>2055</td>\n","      <td>2032</td>\n","      <td>1998</td>\n","      <td>2010</td>\n","      <td>10873</td>\n","      <td>1998</td>\n","      <td>2027</td>\n","      <td>3830</td>\n","      <td>3209</td>\n","      <td>1059</td>\n","      <td>24475</td>\n","      <td>2515</td>\n","      <td>2008</td>\n","      <td>2191</td>\n","      <td>7861</td>\n","      <td>1029</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>1030</td>\n","      <td>5310</td>\n","      <td>1030</td>\n","      <td>5310</td>\n","      <td>1030</td>\n","      <td>5310</td>\n","      <td>2002</td>\n","      <td>3084</td>\n","      <td>2019</td>\n","      <td>9577</td>\n","      <td>2055</td>\n","      <td>1997</td>\n","      <td>2769</td>\n","      <td>2013</td>\n","      <td>1996</td>\n","      <td>5691</td>\n","      <td>1010</td>\n","      <td>15313</td>\n","      <td>999</td>\n","      <td>1001</td>\n","      <td>4553</td>\n","      <td>14406</td>\n","      <td>24138</td>\n","      <td>27268</td>\n","      <td>6633</td>\n","      <td>9316</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>1030</td>\n","      <td>5310</td>\n","      <td>1030</td>\n","      <td>5310</td>\n","      <td>5564</td>\n","      <td>8398</td>\n","      <td>2180</td>\n","      <td>1005</td>\n","      <td>1056</td>\n","      <td>2130</td>\n","      <td>2713</td>\n","      <td>2010</td>\n","      <td>2938</td>\n","      <td>7644</td>\n","      <td>1998</td>\n","      <td>2010</td>\n","      <td>24249</td>\n","      <td>12655</td>\n","      <td>2056</td>\n","      <td>2002</td>\n","      <td>2001</td>\n","      <td>1996</td>\n","      <td>12873</td>\n","      <td>4355</td>\n","      <td>3076</td>\n","      <td>2027</td>\n","      <td>1005</td>\n","      <td>2310</td>\n","      <td>2412</td>\n","      <td>4036</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>1030</td>\n","      <td>5310</td>\n","      <td>1030</td>\n","      <td>5310</td>\n","      <td>3492</td>\n","      <td>2469</td>\n","      <td>1996</td>\n","      <td>3424</td>\n","      <td>1011</td>\n","      <td>5367</td>\n","      <td>4306</td>\n","      <td>3555</td>\n","      <td>2008</td>\n","      <td>1000</td>\n","      <td>7072</td>\n","      <td>2001</td>\n","      <td>2006</td>\n","      <td>1996</td>\n","      <td>10428</td>\n","      <td>1000</td>\n","      <td>1999</td>\n","      <td>7313</td>\n","      <td>1010</td>\n","      <td>2205</td>\n","      <td>1012</td>\n","      <td>2027</td>\n","      <td>2245</td>\n","      <td>5367</td>\n","      <td>2001</td>\n","      <td>1000</td>\n","      <td>27246</td>\n","      <td>1000</td>\n","      <td>1012</td>\n","      <td>1001</td>\n","      <td>2175</td>\n","      <td>2361</td>\n","      <td>1001</td>\n","      <td>2283</td>\n","      <td>11253</td>\n","      <td>4115</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>5 rows Ã— 120 columns</p>\n","</div>"],"text/plain":["    0     1     2     3     4     5     6    ...  113  114  115  116  117  118  119\n","0  1030  5310  1030  5310  1030  5310  1045  ...    0    0    0    0    0    0    0\n","1  1030  5310  1030  5310  2667  2000  6186  ...    0    0    0    0    0    0    0\n","2  1030  5310  1030  5310  1030  5310  2002  ...    0    0    0    0    0    0    0\n","3  1030  5310  1030  5310  5564  8398  2180  ...    0    0    0    0    0    0    0\n","4  1030  5310  1030  5310  3492  2469  1996  ...    0    0    0    0    0    0    0\n","\n","[5 rows x 120 columns]"]},"metadata":{"tags":[]},"execution_count":47}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GynlXdJipn-_","executionInfo":{"status":"ok","timestamp":1607372192571,"user_tz":420,"elapsed":65101,"user":{"displayName":"Steven Su","photoUrl":"","userId":"12872522105664994411"}},"outputId":"93016fd6-c596-4bce-fdc2-f17d9b7b4fbc"},"source":["print(len(tokenizer.vocab))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["30522\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"5baGx3DLzBwy"},"source":["#randomize and split into test and train datasets X,y\n","from sklearn.model_selection import train_test_split\n","\n","X_train, X_test, y_train, y_test = train_test_split(df_x, y, test_size = 0.20, shuffle = True, random_state = 33)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cBcTD8EE1DKV","executionInfo":{"status":"ok","timestamp":1607372192573,"user_tz":420,"elapsed":63294,"user":{"displayName":"Steven Su","photoUrl":"","userId":"12872522105664994411"}},"outputId":"6661ec34-042d-4c18-82f2-5e283edec86c"},"source":["X_train.shape\n"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(4000, 120)"]},"metadata":{"tags":[]},"execution_count":50}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"s7p_U7teCfbB","executionInfo":{"status":"ok","timestamp":1607372539637,"user_tz":420,"elapsed":399,"user":{"displayName":"Steven Su","photoUrl":"","userId":"12872522105664994411"}},"outputId":"a88634d7-bee8-483f-d0c5-e3a94dbae149"},"source":["input_length = X_train.shape[1]\n","VOCAB_LENGTH = len(tokenizer.vocab)\n","EMB_DIM = 200\n","\n","model = tf.keras.Sequential()\n","model.add(layers.Embedding(VOCAB_LENGTH, EMB_DIM, input_length=input_length))\n","model.add(layers.Conv1D(filters=32, kernel_size=8, activation='relu'))\n","model.add(layers.MaxPooling1D(pool_size=2))\n","model.add(layers.Flatten())\n","\n","#model.add(layers.Dense(128, activation='relu'))\n","\n","\n","model.add(layers.Dense(128))\n","model.add(layers.Dropout(rate= 0.5))\n","model.add(layers.Activation('relu'))\n","\n","\n","#model.add(layers.Dense(64, activation='relu'))\n","model.add(layers.Dense(64))\n","model.add(layers.Dropout(rate= 0.5))\n","model.add(layers.Activation('relu'))\n","\n","\n","#model.add(layers.Dense(28, activation='relu'))\n","model.add(layers.Dense(1, activation='sigmoid'))\n","print(model.summary())\n","\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Model: \"sequential_9\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","embedding_9 (Embedding)      (None, 120, 200)          6104400   \n","_________________________________________________________________\n","conv1d_8 (Conv1D)            (None, 113, 32)           51232     \n","_________________________________________________________________\n","max_pooling1d_8 (MaxPooling1 (None, 56, 32)            0         \n","_________________________________________________________________\n","flatten_8 (Flatten)          (None, 1792)              0         \n","_________________________________________________________________\n","dense_98 (Dense)             (None, 128)               229504    \n","_________________________________________________________________\n","dropout_46 (Dropout)         (None, 128)               0         \n","_________________________________________________________________\n","activation_47 (Activation)   (None, 128)               0         \n","_________________________________________________________________\n","dense_99 (Dense)             (None, 64)                8256      \n","_________________________________________________________________\n","dropout_47 (Dropout)         (None, 64)                0         \n","_________________________________________________________________\n","activation_48 (Activation)   (None, 64)                0         \n","_________________________________________________________________\n","dense_100 (Dense)            (None, 1)                 65        \n","=================================================================\n","Total params: 6,393,457\n","Trainable params: 6,393,457\n","Non-trainable params: 0\n","_________________________________________________________________\n","None\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"N2ThGPTrxGb8"},"source":["from tensorflow_addons.optimizers import AdamW\n","import tensorflow_addons as tfa\n","step = tf.Variable(0, trainable=False)\n","schedule = tf.optimizers.schedules.PiecewiseConstantDecay(\n","    [10000, 15000], [1e-0, 1e-1, 1e-2])\n","# lr and wd can be a function or a tensor\n","lr = 1e-1 * schedule(step)\n","wd = lambda: 1e-4 * schedule(step)\n","\n","# ...\n","\n","optimizer = tfa.optimizers.AdamW(learning_rate=lr, weight_decay=wd)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gYlvykgS3vcG","executionInfo":{"status":"ok","timestamp":1607374791831,"user_tz":420,"elapsed":75747,"user":{"displayName":"Steven Su","photoUrl":"","userId":"12872522105664994411"}},"outputId":"effc9fdf-b5e5-4d5c-fb70-4b0152dea8a9"},"source":["# compile network\n","from tensorflow.keras import optimizers\n","\n","opt = optimizers.Adam(learning_rate=.00001, beta_1=0.9, beta_2=0.999, amsgrad=False)\n","model.compile(loss='binary_crossentropy', optimizer= opt, metrics=['accuracy'])\n","# fit network\n","model.fit(X_train, y_train, batch_size = 32, validation_data = (X_test, y_test), epochs=10, verbose=1)\n","# evaluate\n","loss, acc = model.evaluate(X_test, y_test, verbose=1)\n","print('Test Accuracy: %f' % (acc*100))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Epoch 1/10\n","125/125 [==============================] - 8s 61ms/step - loss: 0.2730 - accuracy: 0.9093 - val_loss: 0.4626 - val_accuracy: 0.7760\n","Epoch 2/10\n","125/125 [==============================] - 7s 59ms/step - loss: 0.2685 - accuracy: 0.9045 - val_loss: 0.4664 - val_accuracy: 0.7810\n","Epoch 3/10\n","125/125 [==============================] - 7s 59ms/step - loss: 0.2585 - accuracy: 0.9137 - val_loss: 0.4638 - val_accuracy: 0.7790\n","Epoch 4/10\n","125/125 [==============================] - 7s 59ms/step - loss: 0.2533 - accuracy: 0.9180 - val_loss: 0.4657 - val_accuracy: 0.7800\n","Epoch 5/10\n","125/125 [==============================] - 7s 59ms/step - loss: 0.2406 - accuracy: 0.9190 - val_loss: 0.4688 - val_accuracy: 0.7840\n","Epoch 6/10\n","125/125 [==============================] - 7s 59ms/step - loss: 0.2306 - accuracy: 0.9250 - val_loss: 0.4713 - val_accuracy: 0.7810\n","Epoch 7/10\n","125/125 [==============================] - 7s 59ms/step - loss: 0.2245 - accuracy: 0.9293 - val_loss: 0.4676 - val_accuracy: 0.7810\n","Epoch 8/10\n","125/125 [==============================] - 7s 60ms/step - loss: 0.2180 - accuracy: 0.9337 - val_loss: 0.4726 - val_accuracy: 0.7810\n","Epoch 9/10\n","125/125 [==============================] - 7s 59ms/step - loss: 0.2090 - accuracy: 0.9325 - val_loss: 0.4730 - val_accuracy: 0.7820\n","Epoch 10/10\n","125/125 [==============================] - 7s 59ms/step - loss: 0.1961 - accuracy: 0.9452 - val_loss: 0.4754 - val_accuracy: 0.7810\n","32/32 [==============================] - 0s 3ms/step - loss: 0.4754 - accuracy: 0.7810\n","Test Accuracy: 78.100002\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XN_GWhmKmJJk","executionInfo":{"status":"ok","timestamp":1607374794020,"user_tz":420,"elapsed":328,"user":{"displayName":"Steven Su","photoUrl":"","userId":"12872522105664994411"}},"outputId":"d1d17ca4-868a-4feb-8538-be56f8ec3389"},"source":["from sklearn.metrics import precision_recall_fscore_support\n","y_prediction = model.predict(X_test)\n","y_pred = []\n","for i in y_prediction:\n","    if i >= 0.5:\n","        y_pred.append(1)\n","    else:\n","        y_pred.append(0)    \n","\n","\n","p,r,f,n = precision_recall_fscore_support(y_test, y_pred, average='macro')\n","print('p = ',p, ', r = ', r, ', f = ', f)\n","\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["p =  0.7811278749439426 , r =  0.7808680868086808 , f =  0.78090337838987\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"5j4plTpzG4D-"},"source":["#use if you want to save the model\n","#model.save(\"/content/drive/My Drive/Colab Notebooks/cs410/network02c\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"KPTTFKmaKaHF"},"source":["# Predict using model\n","uncat_tweets = pd.read_json('./data/test.jsonl', lines = True)\n","un_tweets = []\n","uncat_data = list(uncat_tweets[\"response\"])\n","\n","for d in uncat_data:\n","    un_tweets.append(preprocess_text(d))\n","tokenized_un_tweets = [tokenize_tweets(tweet) for tweet in un_tweets]\n","print(str(len(un_tweets)))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"4nzn4OdoKqUF"},"source":["#perform check of input lengths between test and train data\n","count = 0\n","for alist in tokenized_un_tweets:\n","    if len(alist) > count:\n","        count = len(alist)\n","if maxlength < count:\n","    print('error: input of test data input len greater than train data- need to fix')\n","else:\n","    print(\"ok to proceed\")    "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"yWV_o9lTMyPQ"},"source":["tokenized_untweets_padded = pad_sequences(tokenized_un_tweets, maxlen=maxlength, padding = 'post')\n","tokenized_untweets_padded[0]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"YC3SQVl96CLv"},"source":["\n","\n","predictions = model.predict(tokenized_untweets_padded)\n","\n","with open('answer.txt', 'w') as f:\n","    c = 1\n","    s_c = 0\n","    ns_c = 0\n","    for p in predictions:\n","        if p >= .5:\n","            f.write(\"twitter_\" + str(c) + \",\" + \"SARCASM\\n\")\n","            c += 1\n","            s_c += 1\n","        else:\n","            f.write(\"twitter_\" + str(c) + \",\" + \"NOT_SARCASM\\n\")\n","            c += 1\n","            ns_c += 1\n","print(\"# sarcasm: \" + str(s_c))\n","print(\"# not sarcasm: \" + str(ns_c))\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"8N2xsKiGfhpy"},"source":["! git config --global user.email \"susc@colorado.edu\"\n","! git config --global user.name \"steve303\""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"IeaeVHByfVUJ"},"source":["!git stash"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"sMK3akC7N7uW"},"source":["!git add answer.txt\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"QMK33wP_OnQ_"},"source":["!git commit -m \"network_04a\"\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"YpKpm0qCsVqz"},"source":[""],"execution_count":null,"outputs":[]}]}