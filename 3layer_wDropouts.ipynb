{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1541,
     "status": "ok",
     "timestamp": 1606414793764,
     "user": {
      "displayName": "Steven Su",
      "photoUrl": "",
      "userId": "12872522105664994411"
     },
     "user_tz": 420
    },
    "id": "HIe_k81Z-4Hx",
    "outputId": "38a0a6ac-c1d2-4b8b-92c8-28aa9db127b2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Skipping bert-for-tf2 as it is not installed.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "#run if using colab\n",
    "#uninstall if problem during bert tokenization then reinstall below\n",
    "!pip uninstall bert-for-tf2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8164,
     "status": "ok",
     "timestamp": 1606414803089,
     "user": {
      "displayName": "Steven Su",
      "photoUrl": "",
      "userId": "12872522105664994411"
     },
     "user_tz": 420
    },
    "id": "CUj3of3JE5ua",
    "outputId": "080b6d12-0338-4c21-8254-e3d92661479c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting bert-for-tf2\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/18/d3/820ccaf55f1e24b5dd43583ac0da6d86c2d27bbdfffadbba69bafe73ca93/bert-for-tf2-0.14.7.tar.gz (41kB)\n",
      "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 51kB 4.1MB/s eta 0:00:011\n",
      "\u001b[?25hCollecting py-params>=0.9.6\n",
      "  Downloading https://files.pythonhosted.org/packages/a4/bf/c1c70d5315a8677310ea10a41cfc41c5970d9b37c31f9c90d4ab98021fd1/py-params-0.9.7.tar.gz\n",
      "Collecting params-flow>=0.8.0\n",
      "  Downloading https://files.pythonhosted.org/packages/a9/95/ff49f5ebd501f142a6f0aaf42bcfd1c192dc54909d1d9eb84ab031d46056/params-flow-0.8.2.tar.gz\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from params-flow>=0.8.0->bert-for-tf2) (1.18.5)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from params-flow>=0.8.0->bert-for-tf2) (4.41.1)\n",
      "Building wheels for collected packages: bert-for-tf2, py-params, params-flow\n",
      "  Building wheel for bert-for-tf2 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for bert-for-tf2: filename=bert_for_tf2-0.14.7-cp36-none-any.whl size=30539 sha256=034632d3e15589a119959770979e3879042297ec78dbc4c63e298632eb0e967b\n",
      "  Stored in directory: /root/.cache/pip/wheels/e1/f8/e2/b98f79a6b8cc898d8e4102b83acb8a098df7d27500a2bac912\n",
      "  Building wheel for py-params (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for py-params: filename=py_params-0.9.7-cp36-none-any.whl size=7304 sha256=bda7a4050a3f1a2c243111c860a6f2bf6e4e9b22cb0034425c2e89349524096a\n",
      "  Stored in directory: /root/.cache/pip/wheels/67/f5/19/b461849a50aefdf4bab47c4756596e82ee2118b8278e5a1980\n",
      "  Building wheel for params-flow (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for params-flow: filename=params_flow-0.8.2-cp36-none-any.whl size=19475 sha256=4fefce07df6710e7524578599d719b604b9e01d32b6e85e465ea0ce94b96c0b2\n",
      "  Stored in directory: /root/.cache/pip/wheels/08/c8/7f/81c86b9ff2b86e2c477e3914175be03e679e596067dc630c06\n",
      "Successfully built bert-for-tf2 py-params params-flow\n",
      "Installing collected packages: py-params, params-flow, bert-for-tf2\n",
      "Successfully installed bert-for-tf2-0.14.7 params-flow-0.8.2 py-params-0.9.7\n"
     ]
    }
   ],
   "source": [
    "!pip install bert-for-tf2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7108,
     "status": "ok",
     "timestamp": 1606414805993,
     "user": {
      "displayName": "Steven Su",
      "photoUrl": "",
      "userId": "12872522105664994411"
     },
     "user_tz": 420
    },
    "id": "0_Uqg5HN_LUM",
    "outputId": "b6267b1a-31ad-43ee-e753-1f064571bdf9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sentencepiece\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e5/2d/6d4ca4bef9a67070fa1cac508606328329152b1df10bdf31fb6e4e727894/sentencepiece-0.1.94-cp36-cp36m-manylinux2014_x86_64.whl (1.1MB)\n",
      "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1.1MB 10.6MB/s eta 0:00:01\n",
      "\u001b[?25hInstalling collected packages: sentencepiece\n",
      "Successfully installed sentencepiece-0.1.94\n"
     ]
    }
   ],
   "source": [
    "!pip install sentencepiece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9816,
     "status": "ok",
     "timestamp": 1606414809903,
     "user": {
      "displayName": "Steven Su",
      "photoUrl": "",
      "userId": "12872522105664994411"
     },
     "user_tz": 420
    },
    "id": "8E0wwjuJ9Rwr",
    "outputId": "63d85049-8741-40e0-b2f3-364f166ab6ce"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting emoji\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ff/1c/1f1457fe52d0b30cbeebfd578483cedb3e3619108d2d5a21380dfecf8ffd/emoji-0.6.0.tar.gz (51kB)\n",
      "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 51kB 5.3MB/s  eta 0:00:01\n",
      "\u001b[?25hBuilding wheels for collected packages: emoji\n",
      "  Building wheel for emoji (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for emoji: filename=emoji-0.6.0-cp36-none-any.whl size=49716 sha256=f209c8b0a9c7ef738bbf54dad9d8a129436d26606e7233f98e3d4b5b12cbff3c\n",
      "  Stored in directory: /root/.cache/pip/wheels/46/2c/8b/9dcf5216ca68e14e0320e283692dce8ae321cdc01e73e17796\n",
      "Successfully built emoji\n",
      "Installing collected packages: emoji\n",
      "Successfully installed emoji-0.6.0\n"
     ]
    }
   ],
   "source": [
    "!pip install emoji --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9119,
     "status": "ok",
     "timestamp": 1606414810625,
     "user": {
      "displayName": "Steven Su",
      "photoUrl": "",
      "userId": "12872522105664994411"
     },
     "user_tz": 420
    },
    "id": "No_VGWsT9YZx",
    "outputId": "0526733a-2113-491e-df48-c9a3b8584211"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/drive/MyDrive/Colab Notebooks/cs410/CourseProject\n"
     ]
    }
   ],
   "source": [
    "#cd to folder which contain required external files, TEXT_MODEL.py and text_preprocessing.py\n",
    "%cd /content/drive/MyDrive/Colab\\ Notebooks/cs410/CourseProject "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 10779,
     "status": "ok",
     "timestamp": 1606414815050,
     "user": {
      "displayName": "Steven Su",
      "photoUrl": "",
      "userId": "12872522105664994411"
     },
     "user_tz": 420
    },
    "id": "JTVQh4lf6VTe"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf \n",
    "import tensorflow_hub as hub \n",
    "from tensorflow.keras import layers\n",
    "import bert\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import json\n",
    "import re\n",
    "import random\n",
    "import math\n",
    "#from TEXT_MODEL import TEXT_MODEL\n",
    "from TEXT_PREPROCESSING import preprocess_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 16531,
     "status": "ok",
     "timestamp": 1606414824044,
     "user": {
      "displayName": "Steven Su",
      "photoUrl": "",
      "userId": "12872522105664994411"
     },
     "user_tz": 420
    },
    "id": "lKLcMTfG-fZd",
    "outputId": "0924e07f-dc50-4d80-a895-c066ca28769b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            label  ...                                            context\n",
      "0         SARCASM  ...  [A minor child deserves privacy and should be ...\n",
      "1         SARCASM  ...  [@USER @USER Why is he a loser ? He's just a P...\n",
      "2         SARCASM  ...  [Donald J . Trump is guilty as charged . The e...\n",
      "3         SARCASM  ...  [Jamie Raskin tanked Doug Collins . Collins lo...\n",
      "4         SARCASM  ...  [Man ... y â€™ all gone â€œ both sides â€ the apoca...\n",
      "...           ...  ...                                                ...\n",
      "4995  NOT_SARCASM  ...  [@USER Apologies for the inconvenience you fac...\n",
      "4996  NOT_SARCASM  ...  [@USER ðŸ¤” idk tho , I think I â€™ m #hungry . But...\n",
      "4997  NOT_SARCASM  ...  [@USER @USER @USER Peace to you , and two coun...\n",
      "4998  NOT_SARCASM  ...  [Bernie Sanders told Elizabeth Warren in priva...\n",
      "4999  NOT_SARCASM  ...  [PDP PROTEST BRAINSTORMING SESSION Deji : We n...\n",
      "\n",
      "[5000 rows x 3 columns]\n",
      "@USER @USER @USER I don't get this .. obviously you do care or you would've moved right along .. instead you decided to care and troll her ..\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# LOADING DATA\n",
    "categorized_tweets = pd.read_json('./data/train.jsonl', lines = True)\n",
    "categorized_tweets.isnull().values.any()\n",
    "print(categorized_tweets)\n",
    "\n",
    "# PREPROCESSING DATA\n",
    "tweets = []\n",
    "data = list(categorized_tweets[\"response\"])\n",
    "print(data[0])\n",
    "for d in data:\n",
    "    tweets.append(preprocess_text(d))\n",
    "\n",
    "y = categorized_tweets[\"label\"]\n",
    "y = np.array(list(map(lambda x: 1 if x==\"SARCASM\" else 0, y)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 221912,
     "status": "ok",
     "timestamp": 1606415033406,
     "user": {
      "displayName": "Steven Su",
      "photoUrl": "",
      "userId": "12872522105664994411"
     },
     "user_tz": 420
    },
    "id": "MmdV7Bl8HaY9",
    "outputId": "835eb596-6167-4197-a109-1f0b9f845a06"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@USER @USER @USER responds to facts by tossing out frantic insults , then accuses others of being \" triggered by facts \" :rolling_on_the_floor_laughing: :face_with_tears_of_joy: :rolling_on_the_floor_laughing:\n",
      "['@', 'user', '@', 'user', '@', 'user', 'responds', 'to', 'facts', 'by', 'tossing', 'out', 'frantic', 'insults', ',', 'then', 'accuse', '##s', 'others', 'of', 'being', '\"', 'triggered', 'by', 'facts', '\"', ':', 'rolling', '_', 'on', '_', 'the', '_', 'floor', '_', 'laughing', ':', ':', 'face', '_', 'with', '_', 'tears', '_', 'of', '_', 'joy', ':', ':', 'rolling', '_', 'on', '_', 'the', '_', 'floor', '_', 'laughing', ':']\n"
     ]
    }
   ],
   "source": [
    "# TOKENIZING DATA\n",
    "\n",
    "BertTokenizer = bert.bert_tokenization.FullTokenizer\n",
    "\n",
    "bert_layer = hub.KerasLayer(\"https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/3\", trainable=False)\n",
    "vocabulary_file = bert_layer.resolved_object.vocab_file.asset_path.numpy()\n",
    "to_lower_case = bert_layer.resolved_object.do_lower_case.numpy()\n",
    "tokenizer = BertTokenizer(vocabulary_file, to_lower_case)\n",
    "\n",
    "def tokenize_tweets(data):\n",
    "    return tokenizer.convert_tokens_to_ids(tokenizer.tokenize(data))\n",
    "  ##vectorized tweet\n",
    "tokenized_tweets = [tokenize_tweets(tweet) for tweet in tweets]  \n",
    "\n",
    "# tokenized example\n",
    "print(tweets[9])\n",
    "print(tokenizer.tokenize(tweets[9]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1394,
     "status": "ok",
     "timestamp": 1606415034824,
     "user": {
      "displayName": "Steven Su",
      "photoUrl": "",
      "userId": "12872522105664994411"
     },
     "user_tz": 420
    },
    "id": "xZG8FUEA6kFr",
    "outputId": "d71a4733-0f15-4d72-be59-bfe623cca04e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "120"
      ]
     },
     "execution_count": 11,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#find the longest tweet in order to pad shorter tweets w zeros\n",
    "maxlength = 0\n",
    "for alist in tokenized_tweets:\n",
    "    if len(alist) > maxlength:\n",
    "        maxlength = len(alist)\n",
    "        \n",
    "maxlength   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1392,
     "status": "ok",
     "timestamp": 1606415034825,
     "user": {
      "displayName": "Steven Su",
      "photoUrl": "",
      "userId": "12872522105664994411"
     },
     "user_tz": 420
    },
    "id": "CseeOudC9mon",
    "outputId": "3c4095e3-87b7-42a6-987b-d41ffe79ca02"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1030,  5310,  1030,  5310,  1030,  5310,  1045,  2123,  1005,\n",
       "        1056,  2131,  2023,  1012,  1012,  5525,  2017,  2079,  2729,\n",
       "        2030,  2017,  2052,  1005,  2310,  2333,  2157,  2247,  1012,\n",
       "        1012,  2612,  2017,  2787,  2000,  2729,  1998, 18792,  2014,\n",
       "        1012,  1012,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0], dtype=int32)"
      ]
     },
     "execution_count": 12,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#pad the input vector, tweets, so all observations have the same length\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "tokenized_tweets_padded = pad_sequences(tokenized_tweets, maxlen=maxlength, padding = 'post')\n",
    "tokenized_tweets_padded[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1384,
     "status": "ok",
     "timestamp": 1606415034825,
     "user": {
      "displayName": "Steven Su",
      "photoUrl": "",
      "userId": "12872522105664994411"
     },
     "user_tz": 420
    },
    "id": "armOGe1e-hiB",
    "outputId": "8baeef75-f3f6-4534-d079-5d45dba7be9f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 13,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(tokenized_tweets_padded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 443,
     "status": "ok",
     "timestamp": 1606415978406,
     "user": {
      "displayName": "Steven Su",
      "photoUrl": "",
      "userId": "12872522105664994411"
     },
     "user_tz": 420
    },
    "id": "LGrPcsEcHo1J",
    "outputId": "9d8347be-cc4e-4649-cb7f-16d97165ae65"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000, 120)"
      ]
     },
     "execution_count": 25,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_x = pd.DataFrame(tokenized_tweets_padded)\n",
    "df_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 244
    },
    "executionInfo": {
     "elapsed": 440,
     "status": "ok",
     "timestamp": 1606415982390,
     "user": {
      "displayName": "Steven Su",
      "photoUrl": "",
      "userId": "12872522105664994411"
     },
     "user_tz": 420
    },
    "id": "nOjcaVE9KCt1",
    "outputId": "b528aa85-1cf1-46f4-9148-c680482c8b92"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "      <th>32</th>\n",
       "      <th>33</th>\n",
       "      <th>34</th>\n",
       "      <th>35</th>\n",
       "      <th>36</th>\n",
       "      <th>37</th>\n",
       "      <th>38</th>\n",
       "      <th>39</th>\n",
       "      <th>...</th>\n",
       "      <th>80</th>\n",
       "      <th>81</th>\n",
       "      <th>82</th>\n",
       "      <th>83</th>\n",
       "      <th>84</th>\n",
       "      <th>85</th>\n",
       "      <th>86</th>\n",
       "      <th>87</th>\n",
       "      <th>88</th>\n",
       "      <th>89</th>\n",
       "      <th>90</th>\n",
       "      <th>91</th>\n",
       "      <th>92</th>\n",
       "      <th>93</th>\n",
       "      <th>94</th>\n",
       "      <th>95</th>\n",
       "      <th>96</th>\n",
       "      <th>97</th>\n",
       "      <th>98</th>\n",
       "      <th>99</th>\n",
       "      <th>100</th>\n",
       "      <th>101</th>\n",
       "      <th>102</th>\n",
       "      <th>103</th>\n",
       "      <th>104</th>\n",
       "      <th>105</th>\n",
       "      <th>106</th>\n",
       "      <th>107</th>\n",
       "      <th>108</th>\n",
       "      <th>109</th>\n",
       "      <th>110</th>\n",
       "      <th>111</th>\n",
       "      <th>112</th>\n",
       "      <th>113</th>\n",
       "      <th>114</th>\n",
       "      <th>115</th>\n",
       "      <th>116</th>\n",
       "      <th>117</th>\n",
       "      <th>118</th>\n",
       "      <th>119</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1030</td>\n",
       "      <td>5310</td>\n",
       "      <td>1030</td>\n",
       "      <td>5310</td>\n",
       "      <td>1030</td>\n",
       "      <td>5310</td>\n",
       "      <td>1045</td>\n",
       "      <td>2123</td>\n",
       "      <td>1005</td>\n",
       "      <td>1056</td>\n",
       "      <td>2131</td>\n",
       "      <td>2023</td>\n",
       "      <td>1012</td>\n",
       "      <td>1012</td>\n",
       "      <td>5525</td>\n",
       "      <td>2017</td>\n",
       "      <td>2079</td>\n",
       "      <td>2729</td>\n",
       "      <td>2030</td>\n",
       "      <td>2017</td>\n",
       "      <td>2052</td>\n",
       "      <td>1005</td>\n",
       "      <td>2310</td>\n",
       "      <td>2333</td>\n",
       "      <td>2157</td>\n",
       "      <td>2247</td>\n",
       "      <td>1012</td>\n",
       "      <td>1012</td>\n",
       "      <td>2612</td>\n",
       "      <td>2017</td>\n",
       "      <td>2787</td>\n",
       "      <td>2000</td>\n",
       "      <td>2729</td>\n",
       "      <td>1998</td>\n",
       "      <td>18792</td>\n",
       "      <td>2014</td>\n",
       "      <td>1012</td>\n",
       "      <td>1012</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1030</td>\n",
       "      <td>5310</td>\n",
       "      <td>1030</td>\n",
       "      <td>5310</td>\n",
       "      <td>2667</td>\n",
       "      <td>2000</td>\n",
       "      <td>6186</td>\n",
       "      <td>2055</td>\n",
       "      <td>1012</td>\n",
       "      <td>3331</td>\n",
       "      <td>2055</td>\n",
       "      <td>2032</td>\n",
       "      <td>1998</td>\n",
       "      <td>2010</td>\n",
       "      <td>10873</td>\n",
       "      <td>1998</td>\n",
       "      <td>2027</td>\n",
       "      <td>3830</td>\n",
       "      <td>3209</td>\n",
       "      <td>1059</td>\n",
       "      <td>24475</td>\n",
       "      <td>2515</td>\n",
       "      <td>2008</td>\n",
       "      <td>2191</td>\n",
       "      <td>7861</td>\n",
       "      <td>1029</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1030</td>\n",
       "      <td>5310</td>\n",
       "      <td>1030</td>\n",
       "      <td>5310</td>\n",
       "      <td>1030</td>\n",
       "      <td>5310</td>\n",
       "      <td>2002</td>\n",
       "      <td>3084</td>\n",
       "      <td>2019</td>\n",
       "      <td>9577</td>\n",
       "      <td>2055</td>\n",
       "      <td>1997</td>\n",
       "      <td>2769</td>\n",
       "      <td>2013</td>\n",
       "      <td>1996</td>\n",
       "      <td>5691</td>\n",
       "      <td>1010</td>\n",
       "      <td>15313</td>\n",
       "      <td>999</td>\n",
       "      <td>1001</td>\n",
       "      <td>4553</td>\n",
       "      <td>14406</td>\n",
       "      <td>24138</td>\n",
       "      <td>27268</td>\n",
       "      <td>6633</td>\n",
       "      <td>9316</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1030</td>\n",
       "      <td>5310</td>\n",
       "      <td>1030</td>\n",
       "      <td>5310</td>\n",
       "      <td>5564</td>\n",
       "      <td>8398</td>\n",
       "      <td>2180</td>\n",
       "      <td>1005</td>\n",
       "      <td>1056</td>\n",
       "      <td>2130</td>\n",
       "      <td>2713</td>\n",
       "      <td>2010</td>\n",
       "      <td>2938</td>\n",
       "      <td>7644</td>\n",
       "      <td>1998</td>\n",
       "      <td>2010</td>\n",
       "      <td>24249</td>\n",
       "      <td>12655</td>\n",
       "      <td>2056</td>\n",
       "      <td>2002</td>\n",
       "      <td>2001</td>\n",
       "      <td>1996</td>\n",
       "      <td>12873</td>\n",
       "      <td>4355</td>\n",
       "      <td>3076</td>\n",
       "      <td>2027</td>\n",
       "      <td>1005</td>\n",
       "      <td>2310</td>\n",
       "      <td>2412</td>\n",
       "      <td>4036</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1030</td>\n",
       "      <td>5310</td>\n",
       "      <td>1030</td>\n",
       "      <td>5310</td>\n",
       "      <td>3492</td>\n",
       "      <td>2469</td>\n",
       "      <td>1996</td>\n",
       "      <td>3424</td>\n",
       "      <td>1011</td>\n",
       "      <td>5367</td>\n",
       "      <td>4306</td>\n",
       "      <td>3555</td>\n",
       "      <td>2008</td>\n",
       "      <td>1000</td>\n",
       "      <td>7072</td>\n",
       "      <td>2001</td>\n",
       "      <td>2006</td>\n",
       "      <td>1996</td>\n",
       "      <td>10428</td>\n",
       "      <td>1000</td>\n",
       "      <td>1999</td>\n",
       "      <td>7313</td>\n",
       "      <td>1010</td>\n",
       "      <td>2205</td>\n",
       "      <td>1012</td>\n",
       "      <td>2027</td>\n",
       "      <td>2245</td>\n",
       "      <td>5367</td>\n",
       "      <td>2001</td>\n",
       "      <td>1000</td>\n",
       "      <td>27246</td>\n",
       "      <td>1000</td>\n",
       "      <td>1012</td>\n",
       "      <td>1001</td>\n",
       "      <td>2175</td>\n",
       "      <td>2361</td>\n",
       "      <td>1001</td>\n",
       "      <td>2283</td>\n",
       "      <td>11253</td>\n",
       "      <td>4115</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 120 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    0     1     2     3     4     5     6    ...  113  114  115  116  117  118  119\n",
       "0  1030  5310  1030  5310  1030  5310  1045  ...    0    0    0    0    0    0    0\n",
       "1  1030  5310  1030  5310  2667  2000  6186  ...    0    0    0    0    0    0    0\n",
       "2  1030  5310  1030  5310  1030  5310  2002  ...    0    0    0    0    0    0    0\n",
       "3  1030  5310  1030  5310  5564  8398  2180  ...    0    0    0    0    0    0    0\n",
       "4  1030  5310  1030  5310  3492  2469  1996  ...    0    0    0    0    0    0    0\n",
       "\n",
       "[5 rows x 120 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_x.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 396,
     "status": "ok",
     "timestamp": 1606415990638,
     "user": {
      "displayName": "Steven Su",
      "photoUrl": "",
      "userId": "12872522105664994411"
     },
     "user_tz": 420
    },
    "id": "GynlXdJipn-_",
    "outputId": "ef6aede7-4955-44fe-abde-6d1f090ba0fe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30522\n"
     ]
    }
   ],
   "source": [
    "print(len(tokenizer.vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "executionInfo": {
     "elapsed": 462,
     "status": "ok",
     "timestamp": 1606415997748,
     "user": {
      "displayName": "Steven Su",
      "photoUrl": "",
      "userId": "12872522105664994411"
     },
     "user_tz": 420
    },
    "id": "5baGx3DLzBwy"
   },
   "outputs": [],
   "source": [
    "#randomize and split into test and train datasets X,y\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_x, y, test_size = 0.20, shuffle = True, random_state = 33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 612,
     "status": "ok",
     "timestamp": 1606430734650,
     "user": {
      "displayName": "Steven Su",
      "photoUrl": "",
      "userId": "12872522105664994411"
     },
     "user_tz": 420
    },
    "id": "cBcTD8EE1DKV",
    "outputId": "329d8baa-f6a7-4270-86b0-04fdaea1cc1f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4000, 120)"
      ]
     },
     "execution_count": 116,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 517,
     "status": "ok",
     "timestamp": 1606430164750,
     "user": {
      "displayName": "Steven Su",
      "photoUrl": "",
      "userId": "12872522105664994411"
     },
     "user_tz": 420
    },
    "id": "s7p_U7teCfbB",
    "outputId": "e0912a41-d056-49e1-d2d8-89984435d6a6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_17\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_15 (Embedding)     (None, 120, 200)          6104400   \n",
      "_________________________________________________________________\n",
      "conv1d_15 (Conv1D)           (None, 113, 32)           51232     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_15 (MaxPooling (None, 56, 32)            0         \n",
      "_________________________________________________________________\n",
      "flatten_15 (Flatten)         (None, 1792)              0         \n",
      "_________________________________________________________________\n",
      "dense_51 (Dense)             (None, 512)               918016    \n",
      "_________________________________________________________________\n",
      "dropout_16 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_52 (Dense)             (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dropout_17 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "activation_10 (Activation)   (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_53 (Dense)             (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dense_54 (Dense)             (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 7,238,001\n",
      "Trainable params: 7,238,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "input_length = X_train.shape[1]\n",
    "VOCAB_LENGTH = len(tokenizer.vocab)\n",
    "EMB_DIM = 200\n",
    "\n",
    "model = tf.keras.Sequential()\n",
    "model.add(layers.Embedding(VOCAB_LENGTH, EMB_DIM, input_length=input_length))\n",
    "#model.add(layers.Dense(64, activation=relu ))\n",
    "#model.add(layers.Dense(units=1, activation=sigmoid))\n",
    "\n",
    "model.add(layers.Conv1D(filters=32, kernel_size=8, activation='relu'))\n",
    "model.add(layers.MaxPooling1D(pool_size=2))\n",
    "model.add(layers.Flatten())\n",
    "\n",
    "#model.add(layers.Dense(128, activation='relu'))\n",
    "model.add(layers.Dense(512))\n",
    "model.add(layers.Dropout(rate= 0.5))\n",
    "model.add(layers.Activation('relu'))\n",
    "\n",
    "#model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dense(256))\n",
    "model.add(layers.Dropout(rate= 0.5))\n",
    "model.add(layers.Activation('relu'))\n",
    "\n",
    "model.add(layers.Dense(128, activation='relu'))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))\n",
    "print(model.summary())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 208987,
     "status": "ok",
     "timestamp": 1606430075015,
     "user": {
      "displayName": "Steven Su",
      "photoUrl": "",
      "userId": "12872522105664994411"
     },
     "user_tz": 420
    },
    "id": "gYlvykgS3vcG",
    "outputId": "7c16d92d-fa1e-4529-8ad5-46cac2dd03e4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "125/125 [==============================] - 11s 85ms/step - loss: 0.6857 - accuracy: 0.5598 - val_loss: 0.6596 - val_accuracy: 0.6460\n",
      "Epoch 2/20\n",
      "125/125 [==============================] - 10s 83ms/step - loss: 0.6482 - accuracy: 0.6342 - val_loss: 0.6214 - val_accuracy: 0.6590\n",
      "Epoch 3/20\n",
      "125/125 [==============================] - 10s 82ms/step - loss: 0.6067 - accuracy: 0.6795 - val_loss: 0.5731 - val_accuracy: 0.7200\n",
      "Epoch 4/20\n",
      "125/125 [==============================] - 10s 82ms/step - loss: 0.5158 - accuracy: 0.7558 - val_loss: 0.5005 - val_accuracy: 0.7630\n",
      "Epoch 5/20\n",
      "125/125 [==============================] - 10s 81ms/step - loss: 0.3953 - accuracy: 0.8390 - val_loss: 0.4824 - val_accuracy: 0.7740\n",
      "Epoch 6/20\n",
      "125/125 [==============================] - 10s 83ms/step - loss: 0.2444 - accuracy: 0.9107 - val_loss: 0.5217 - val_accuracy: 0.7850\n",
      "Epoch 7/20\n",
      "125/125 [==============================] - 10s 83ms/step - loss: 0.1181 - accuracy: 0.9622 - val_loss: 0.6444 - val_accuracy: 0.7710\n",
      "Epoch 8/20\n",
      "125/125 [==============================] - 10s 82ms/step - loss: 0.0470 - accuracy: 0.9887 - val_loss: 0.8525 - val_accuracy: 0.7660\n",
      "Epoch 9/20\n",
      "125/125 [==============================] - 10s 83ms/step - loss: 0.0244 - accuracy: 0.9952 - val_loss: 0.9407 - val_accuracy: 0.7690\n",
      "Epoch 10/20\n",
      "125/125 [==============================] - 10s 82ms/step - loss: 0.0113 - accuracy: 0.9985 - val_loss: 1.0897 - val_accuracy: 0.7550\n",
      "Epoch 11/20\n",
      "125/125 [==============================] - 10s 82ms/step - loss: 0.0076 - accuracy: 0.9992 - val_loss: 1.1353 - val_accuracy: 0.7560\n",
      "Epoch 12/20\n",
      "125/125 [==============================] - 10s 84ms/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 1.1929 - val_accuracy: 0.7650\n",
      "Epoch 13/20\n",
      "125/125 [==============================] - 10s 82ms/step - loss: 0.0039 - accuracy: 0.9995 - val_loss: 1.2798 - val_accuracy: 0.7760\n",
      "Epoch 14/20\n",
      "125/125 [==============================] - 10s 82ms/step - loss: 0.0039 - accuracy: 0.9998 - val_loss: 1.2907 - val_accuracy: 0.7670\n",
      "Epoch 15/20\n",
      "125/125 [==============================] - 10s 80ms/step - loss: 0.0032 - accuracy: 0.9998 - val_loss: 1.3366 - val_accuracy: 0.7750\n",
      "Epoch 16/20\n",
      "125/125 [==============================] - 10s 81ms/step - loss: 0.0020 - accuracy: 0.9998 - val_loss: 1.3809 - val_accuracy: 0.7570\n",
      "Epoch 17/20\n",
      "125/125 [==============================] - 10s 81ms/step - loss: 0.0014 - accuracy: 0.9998 - val_loss: 1.4361 - val_accuracy: 0.7650\n",
      "Epoch 18/20\n",
      "125/125 [==============================] - 10s 83ms/step - loss: 0.0061 - accuracy: 0.9992 - val_loss: 1.3659 - val_accuracy: 0.7520\n",
      "Epoch 19/20\n",
      "125/125 [==============================] - 10s 82ms/step - loss: 0.0034 - accuracy: 0.9995 - val_loss: 1.3826 - val_accuracy: 0.7540\n",
      "Epoch 20/20\n",
      "125/125 [==============================] - 10s 82ms/step - loss: 0.0034 - accuracy: 0.9995 - val_loss: 1.4310 - val_accuracy: 0.7520\n",
      "32/32 [==============================] - 0s 12ms/step - loss: 1.4310 - accuracy: 0.7520\n",
      "Test Accuracy: 75.199997\n"
     ]
    }
   ],
   "source": [
    "# compile network\n",
    "from tensorflow.keras import optimizers\n",
    "opt = optimizers.Adam(learning_rate=.0001, beta_1=0.9, beta_2=0.999, amsgrad=False)\n",
    "model.compile(loss='binary_crossentropy', optimizer= opt, metrics=['accuracy'])\n",
    "# fit network\n",
    "model.fit(X_train, y_train, batch_size = 32, validation_data = (X_test, y_test), epochs=20, verbose=1)\n",
    "# evaluate\n",
    "loss, acc = model.evaluate(X_test, y_test, verbose=1)\n",
    "print('Test Accuracy: %f' % (acc*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "executionInfo": {
     "elapsed": 935,
     "status": "ok",
     "timestamp": 1606420391576,
     "user": {
      "displayName": "Steven Su",
      "photoUrl": "",
      "userId": "12872522105664994411"
     },
     "user_tz": 420
    },
    "id": "5j4plTpzG4D-"
   },
   "outputs": [],
   "source": [
    "#use if you want to save the model\n",
    "#model.save(\"/content/drive/My Drive/Colab Notebooks/cs410/model1.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3372,
     "status": "ok",
     "timestamp": 1606428522980,
     "user": {
      "displayName": "Steven Su",
      "photoUrl": "",
      "userId": "12872522105664994411"
     },
     "user_tz": 420
    },
    "id": "KPTTFKmaKaHF",
    "outputId": "94b6bd68-9a98-464a-f3da-9b9f4a8a54cd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1800\n"
     ]
    }
   ],
   "source": [
    "# Predict using model\n",
    "uncat_tweets = pd.read_json('./data/test.jsonl', lines = True)\n",
    "un_tweets = []\n",
    "uncat_data = list(uncat_tweets[\"response\"])\n",
    "\n",
    "for d in uncat_data:\n",
    "    un_tweets.append(preprocess_text(d))\n",
    "tokenized_un_tweets = [tokenize_tweets(tweet) for tweet in un_tweets]\n",
    "print(str(len(un_tweets)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 502,
     "status": "ok",
     "timestamp": 1606428527717,
     "user": {
      "displayName": "Steven Su",
      "photoUrl": "",
      "userId": "12872522105664994411"
     },
     "user_tz": 420
    },
    "id": "4nzn4OdoKqUF",
    "outputId": "8a9d1de1-5f27-4414-d12d-d16371021eba"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ok to proceed\n"
     ]
    }
   ],
   "source": [
    "#perform check of input lengths between test and train data\n",
    "count = 0\n",
    "for alist in tokenized_un_tweets:\n",
    "    if len(alist) > count:\n",
    "        count = len(alist)\n",
    "if maxlength < count:\n",
    "    print('error: input of test data input len greater than train data- need to fix')\n",
    "else:\n",
    "    print(\"ok to proceed\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 394,
     "status": "ok",
     "timestamp": 1606428533034,
     "user": {
      "displayName": "Steven Su",
      "photoUrl": "",
      "userId": "12872522105664994411"
     },
     "user_tz": 420
    },
    "id": "yWV_o9lTMyPQ",
    "outputId": "2883714c-0442-4fd8-b14b-2eafa2cd1477"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1030,  5310,  1030,  5310,  1030,  5310,  2026,  1017,  2095,\n",
       "        2214,  1010,  2008,  2074,  2736,  3752, 28898,  1998,  2059,\n",
       "        2356,  2033,  1024,  1000,  1037,  7677, 13008,  2339,  2122,\n",
       "        2111,  2467,  2667,  2000, 17542,  2619,  2006, 10474,  1010,\n",
       "        2667,  2000,  9811,  2066,  2008,  3084,  2068,  2488,  3209,\n",
       "        1029,  1000,  1012,  2000,  2029,  1045,  3880,  1000,  8909,\n",
       "        2243,  1000,  1010,  1998,  2002,  2074,  1000, 12731,  2480,\n",
       "        7570,  2229,  5506,  1000,  1012, 10047,  2061,  7098,  1012,\n",
       "        1026, 24471,  2140,  1028,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0], dtype=int32)"
      ]
     },
     "execution_count": 102,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_untweets_padded = pad_sequences(tokenized_un_tweets, maxlen=maxlength, padding = 'post')\n",
    "tokenized_untweets_padded[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1165,
     "status": "ok",
     "timestamp": 1606428537706,
     "user": {
      "displayName": "Steven Su",
      "photoUrl": "",
      "userId": "12872522105664994411"
     },
     "user_tz": 420
    },
    "id": "YC3SQVl96CLv",
    "outputId": "02678a8a-54af-4bb3-d6a7-afea5077f9d4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# sarcasm: 1128\n",
      "# not sarcasm: 672\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "predictions = model.predict(tokenized_untweets_padded)\n",
    "\n",
    "with open('answer.txt', 'w') as f:\n",
    "    c = 1\n",
    "    s_c = 0\n",
    "    ns_c = 0\n",
    "    for p in predictions:\n",
    "        if p >= .5:\n",
    "            f.write(\"twitter_\" + str(c) + \",\" + \"SARCASM\\n\")\n",
    "            c += 1\n",
    "            s_c += 1\n",
    "        else:\n",
    "            f.write(\"twitter_\" + str(c) + \",\" + \"NOT_SARCASM\\n\")\n",
    "            c += 1\n",
    "            ns_c += 1\n",
    "print(\"# sarcasm: \" + str(s_c))\n",
    "print(\"# not sarcasm: \" + str(ns_c))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1358,
     "status": "ok",
     "timestamp": 1606428545538,
     "user": {
      "displayName": "Steven Su",
      "photoUrl": "",
      "userId": "12872522105664994411"
     },
     "user_tz": 420
    },
    "id": "dvVtXamaN4lJ",
    "outputId": "47ca4f07-aaa6-4ff7-95f7-c86075d67608"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From https://github.com/steve303/CourseProject\n",
      "   c4e8b49..b21d657  main       -> origin/main\n",
      "Already up to date.\n"
     ]
    }
   ],
   "source": [
    "#!git pull"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "executionInfo": {
     "elapsed": 411,
     "status": "ok",
     "timestamp": 1606428551169,
     "user": {
      "displayName": "Steven Su",
      "photoUrl": "",
      "userId": "12872522105664994411"
     },
     "user_tz": 420
    },
    "id": "sMK3akC7N7uW"
   },
   "outputs": [],
   "source": [
    "#!git add answer.txt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "executionInfo": {
     "elapsed": 684,
     "status": "ok",
     "timestamp": 1606428557337,
     "user": {
      "displayName": "Steven Su",
      "photoUrl": "",
      "userId": "12872522105664994411"
     },
     "user_tz": 420
    },
    "id": "_ljkYiGQOSvE"
   },
   "outputs": [],
   "source": [
    "! git config --global user.email \"susc@colorado.edu\"\n",
    "! git config --global user.name \"steve303\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 673,
     "status": "ok",
     "timestamp": 1606428567390,
     "user": {
      "displayName": "Steven Su",
      "photoUrl": "",
      "userId": "12872522105664994411"
     },
     "user_tz": 420
    },
    "id": "QMK33wP_OnQ_",
    "outputId": "d19c5c41-c9bc-40a9-a84b-7adc3e4e27f8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[main 1f21537] add answer.txt\n",
      " 1 file changed, 332 insertions(+), 332 deletions(-)\n"
     ]
    }
   ],
   "source": [
    "!git commit -m \"add answer.txt\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 931,
     "status": "ok",
     "timestamp": 1606422294630,
     "user": {
      "displayName": "Steven Su",
      "photoUrl": "",
      "userId": "12872522105664994411"
     },
     "user_tz": 420
    },
    "id": "HZHwUZJ1Oq1M",
    "outputId": "f902752b-629c-414e-b79a-96e4858c1188"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fatal: could not read Username for 'https://github.com': No such device or address\n"
     ]
    }
   ],
   "source": [
    "#this doesn't work need to use below\n",
    "!git push"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4531,
     "status": "ok",
     "timestamp": 1606428587348,
     "user": {
      "displayName": "Steven Su",
      "photoUrl": "",
      "userId": "12872522105664994411"
     },
     "user_tz": 420
    },
    "id": "-XMYSv3NP3kH",
    "outputId": "416ffee9-6f6a-4a8b-f74f-74a7dec2dcec"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counting objects: 3, done.\n",
      "Delta compression using up to 2 threads.\n",
      "Compressing objects: 100% (3/3), done.\n",
      "Writing objects: 100% (3/3), 2.16 KiB | 315.00 KiB/s, done.\n",
      "Total 3 (delta 2), reused 0 (delta 0)\n",
      "remote: Resolving deltas: 100% (2/2), completed with 2 local objects.\u001b[K\n",
      "To https://github.com/steve303/CourseProject.git\n",
      "   b21d657..1f21537  main -> main\n"
     ]
    }
   ],
   "source": [
    "#!git push https://steve303:password@github.com/steve303/CourseProject.git"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyOl2L8QA/TClBAFwIG41eHD",
   "collapsed_sections": [],
   "mount_file_id": "1xfyV0_yB3OkLVKR3-IErLDAcYsRL9oc7",
   "name": "3layer_wDropouts.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
