{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"ktm0.ipynb","provenance":[{"file_id":"1nL6y1v0ioygQf-QoOMeIHTnt2__XCMDZ","timestamp":1606193337350}],"mount_file_id":"1bNci76MiaVaAU10SGr6GfawYVIG3ASKd","authorship_tag":"ABX9TyMbgjzksN9PKa9emQVxnNy8"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QqoTXZyLnWcZ","executionInfo":{"status":"ok","timestamp":1606256060793,"user_tz":420,"elapsed":12107,"user":{"displayName":"Steven Su","photoUrl":"","userId":"12872522105664994411"}},"outputId":"e5c3b650-ed7b-480e-f876-1e660cf0d8d2"},"source":["!pip install keras-bert"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Collecting keras-bert\n","  Downloading https://files.pythonhosted.org/packages/e2/7f/95fabd29f4502924fa3f09ff6538c5a7d290dfef2c2fe076d3d1a16e08f0/keras-bert-0.86.0.tar.gz\n","Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from keras-bert) (1.18.5)\n","Requirement already satisfied: Keras>=2.4.3 in /usr/local/lib/python3.6/dist-packages (from keras-bert) (2.4.3)\n","Collecting keras-transformer>=0.38.0\n","  Downloading https://files.pythonhosted.org/packages/89/6c/d6f0c164f4cc16fbc0d0fea85f5526e87a7d2df7b077809e422a7e626150/keras-transformer-0.38.0.tar.gz\n","Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from Keras>=2.4.3->keras-bert) (1.4.1)\n","Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from Keras>=2.4.3->keras-bert) (2.10.0)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from Keras>=2.4.3->keras-bert) (3.13)\n","Collecting keras-pos-embd>=0.11.0\n","  Downloading https://files.pythonhosted.org/packages/09/70/b63ed8fc660da2bb6ae29b9895401c628da5740c048c190b5d7107cadd02/keras-pos-embd-0.11.0.tar.gz\n","Collecting keras-multi-head>=0.27.0\n","  Downloading https://files.pythonhosted.org/packages/e6/32/45adf2549450aca7867deccfa04af80a0ab1ca139af44b16bc669e0e09cd/keras-multi-head-0.27.0.tar.gz\n","Collecting keras-layer-normalization>=0.14.0\n","  Downloading https://files.pythonhosted.org/packages/a4/0e/d1078df0494bac9ce1a67954e5380b6e7569668f0f3b50a9531c62c1fc4a/keras-layer-normalization-0.14.0.tar.gz\n","Collecting keras-position-wise-feed-forward>=0.6.0\n","  Downloading https://files.pythonhosted.org/packages/e3/59/f0faa1037c033059e7e9e7758e6c23b4d1c0772cd48de14c4b6fd4033ad5/keras-position-wise-feed-forward-0.6.0.tar.gz\n","Collecting keras-embed-sim>=0.8.0\n","  Downloading https://files.pythonhosted.org/packages/57/ef/61a1e39082c9e1834a2d09261d4a0b69f7c818b359216d4e1912b20b1c86/keras-embed-sim-0.8.0.tar.gz\n","Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from h5py->Keras>=2.4.3->keras-bert) (1.15.0)\n","Collecting keras-self-attention==0.46.0\n","  Downloading https://files.pythonhosted.org/packages/15/6b/c804924a056955fa1f3ff767945187103cfc851ba9bd0fc5a6c6bc18e2eb/keras-self-attention-0.46.0.tar.gz\n","Building wheels for collected packages: keras-bert, keras-transformer, keras-pos-embd, keras-multi-head, keras-layer-normalization, keras-position-wise-feed-forward, keras-embed-sim, keras-self-attention\n","  Building wheel for keras-bert (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for keras-bert: filename=keras_bert-0.86.0-cp36-none-any.whl size=34145 sha256=b2e241de581449ecfa44eb63236b5cd907be150ff1c483114d137c67fe1bd85b\n","  Stored in directory: /root/.cache/pip/wheels/66/f0/b1/748128b58562fc9e31b907bb5e2ab6a35eb37695e83911236b\n","  Building wheel for keras-transformer (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for keras-transformer: filename=keras_transformer-0.38.0-cp36-none-any.whl size=12942 sha256=2362cdce9cf4a9c69c3b5672e057e1d9cd1e8918ce994cef9815f310d682a380\n","  Stored in directory: /root/.cache/pip/wheels/e5/fb/3a/37b2b9326c799aa010ae46a04ddb04f320d8c77c0b7e837f4e\n","  Building wheel for keras-pos-embd (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for keras-pos-embd: filename=keras_pos_embd-0.11.0-cp36-none-any.whl size=7554 sha256=0f91aa8f4bf9f85420a2488593d45ba7b6c1f05dc81449c73f2b3d495394c9e3\n","  Stored in directory: /root/.cache/pip/wheels/5b/a1/a0/ce6b1d49ba1a9a76f592e70cf297b05c96bc9f418146761032\n","  Building wheel for keras-multi-head (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for keras-multi-head: filename=keras_multi_head-0.27.0-cp36-none-any.whl size=15612 sha256=fddcb10ea46ab5a260dbe7094491f09c3df91f1b295612a23fbc4b84897b2677\n","  Stored in directory: /root/.cache/pip/wheels/b5/b4/49/0a0c27dcb93c13af02fea254ff51d1a43a924dd4e5b7a7164d\n","  Building wheel for keras-layer-normalization (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for keras-layer-normalization: filename=keras_layer_normalization-0.14.0-cp36-none-any.whl size=5268 sha256=d35723e2d9eabb3e23fb812e135090b679c66245af518790695a1cdecee41c86\n","  Stored in directory: /root/.cache/pip/wheels/54/80/22/a638a7d406fd155e507aa33d703e3fa2612b9eb7bb4f4fe667\n","  Building wheel for keras-position-wise-feed-forward (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for keras-position-wise-feed-forward: filename=keras_position_wise_feed_forward-0.6.0-cp36-none-any.whl size=5626 sha256=593ac7861a4dc58a41d212b989cbfcef31f209207a0ee3008333249d14189ae4\n","  Stored in directory: /root/.cache/pip/wheels/39/e2/e2/3514fef126a00574b13bc0b9e23891800158df3a3c19c96e3b\n","  Building wheel for keras-embed-sim (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for keras-embed-sim: filename=keras_embed_sim-0.8.0-cp36-none-any.whl size=4559 sha256=775bf69d0eb1c7fe40b9f4905c2100d86c0b5f77990741e0030956b32904e560\n","  Stored in directory: /root/.cache/pip/wheels/49/45/8b/c111f6cc8bec253e984677de73a6f4f5d2f1649f42aac191c8\n","  Building wheel for keras-self-attention (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for keras-self-attention: filename=keras_self_attention-0.46.0-cp36-none-any.whl size=17278 sha256=f7fd3f1984fdb5bb08ff1e5006aebac18c50767f1c4c0f8bbd19ce8858691257\n","  Stored in directory: /root/.cache/pip/wheels/d2/2e/80/fec4c05eb23c8e13b790e26d207d6e0ffe8013fad8c6bdd4d2\n","Successfully built keras-bert keras-transformer keras-pos-embd keras-multi-head keras-layer-normalization keras-position-wise-feed-forward keras-embed-sim keras-self-attention\n","Installing collected packages: keras-pos-embd, keras-self-attention, keras-multi-head, keras-layer-normalization, keras-position-wise-feed-forward, keras-embed-sim, keras-transformer, keras-bert\n","Successfully installed keras-bert-0.86.0 keras-embed-sim-0.8.0 keras-layer-normalization-0.14.0 keras-multi-head-0.27.0 keras-pos-embd-0.11.0 keras-position-wise-feed-forward-0.6.0 keras-self-attention-0.46.0 keras-transformer-0.38.0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"jviywGyWyKsA","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1606256096475,"user_tz":420,"elapsed":2843,"user":{"displayName":"Steven Su","photoUrl":"","userId":"12872522105664994411"}},"outputId":"8804d257-1584-4bd4-edbb-9c71c9e90eef"},"source":["!pip install bert-tensorflow"],"execution_count":5,"outputs":[{"output_type":"stream","text":["Collecting bert-tensorflow\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/20/16/0f9376af49c6adcfbaf2470a8f500105a74dd803aa54ac0110af445837b5/bert_tensorflow-1.0.4-py2.py3-none-any.whl (64kB)\n","\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà                           | 10kB 21.0MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                     | 20kB 15.4MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                | 30kB 13.6MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç           | 40kB 13.5MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç      | 51kB 11.1MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 61kB 11.4MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 71kB 6.2MB/s \n","\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from bert-tensorflow) (1.15.0)\n","Installing collected packages: bert-tensorflow\n","Successfully installed bert-tensorflow-1.0.4\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jU_UfxxrnnRz","executionInfo":{"status":"ok","timestamp":1606256145024,"user_tz":420,"elapsed":3723,"user":{"displayName":"Steven Su","photoUrl":"","userId":"12872522105664994411"}},"outputId":"321f7d51-237c-421e-82c0-a05c5a5bb3a6"},"source":["!pip install emoji --upgrade"],"execution_count":9,"outputs":[{"output_type":"stream","text":["Collecting emoji\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ff/1c/1f1457fe52d0b30cbeebfd578483cedb3e3619108d2d5a21380dfecf8ffd/emoji-0.6.0.tar.gz (51kB)\n","\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                         | 10kB 21.6MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                   | 20kB 28.4MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé            | 30kB 24.4MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä      | 40kB 22.9MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 51kB 7.1MB/s \n","\u001b[?25hBuilding wheels for collected packages: emoji\n","  Building wheel for emoji (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for emoji: filename=emoji-0.6.0-cp36-none-any.whl size=49716 sha256=d8b31c7009662e32223d2b5ca5a30bd667bfa3e11e22f3450790c197030ead2b\n","  Stored in directory: /root/.cache/pip/wheels/46/2c/8b/9dcf5216ca68e14e0320e283692dce8ae321cdc01e73e17796\n","Successfully built emoji\n","Installing collected packages: emoji\n","Successfully installed emoji-0.6.0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ssU0EV7mtSHa","executionInfo":{"status":"ok","timestamp":1606256119987,"user_tz":420,"elapsed":321,"user":{"displayName":"Steven Su","photoUrl":"","userId":"12872522105664994411"}},"outputId":"1c4e3542-296f-4d4e-bfce-9a19d6cce36e"},"source":["%cd /content/drive/MyDrive/Colab\\ Notebooks/cs410/CourseProject  #cd to folder which contain required external files, TEXT_MODEL.py and text_preprocessing.py\n"],"execution_count":7,"outputs":[{"output_type":"stream","text":["/content/drive/MyDrive/Colab Notebooks/cs410/CourseProject\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"VuFsypc3krUl","executionInfo":{"status":"ok","timestamp":1606256152427,"user_tz":420,"elapsed":365,"user":{"displayName":"Steven Su","photoUrl":"","userId":"12872522105664994411"}}},"source":["import tensorflow as tf \n","import tensorflow_hub as hub \n","from tensorflow.keras import layers\n","import bert\n","import numpy as np \n","import pandas as pd \n","import json\n","import re\n","import random\n","import math\n","from tensorflow.keras.preprocessing.text import Tokenizer\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\n","from TEXT_MODEL import TEXT_MODEL\n","from TEXT_PREPROCESSING import preprocess_text\n"],"execution_count":10,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dCWU2RBQwafE","executionInfo":{"status":"ok","timestamp":1606256194689,"user_tz":420,"elapsed":1694,"user":{"displayName":"Steven Su","photoUrl":"","userId":"12872522105664994411"}},"outputId":"5d7b0ed0-6489-43a4-a217-5e0d16ec46e9"},"source":["# LOADING DATA\n","categorized_tweets = pd.read_json('./data/train.jsonl', lines = True)\n","categorized_tweets.isnull().values.any()\n","print(categorized_tweets)"],"execution_count":12,"outputs":[{"output_type":"stream","text":["            label  ...                                            context\n","0         SARCASM  ...  [A minor child deserves privacy and should be ...\n","1         SARCASM  ...  [@USER @USER Why is he a loser ? He's just a P...\n","2         SARCASM  ...  [Donald J . Trump is guilty as charged . The e...\n","3         SARCASM  ...  [Jamie Raskin tanked Doug Collins . Collins lo...\n","4         SARCASM  ...  [Man ... y ‚Äô all gone ‚Äú both sides ‚Äù the apoca...\n","...           ...  ...                                                ...\n","4995  NOT_SARCASM  ...  [@USER Apologies for the inconvenience you fac...\n","4996  NOT_SARCASM  ...  [@USER ü§î idk tho , I think I ‚Äô m #hungry . But...\n","4997  NOT_SARCASM  ...  [@USER @USER @USER Peace to you , and two coun...\n","4998  NOT_SARCASM  ...  [Bernie Sanders told Elizabeth Warren in priva...\n","4999  NOT_SARCASM  ...  [PDP PROTEST BRAINSTORMING SESSION Deji : We n...\n","\n","[5000 rows x 3 columns]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7cI3ulcIwfSr","executionInfo":{"status":"ok","timestamp":1606256201064,"user_tz":420,"elapsed":4044,"user":{"displayName":"Steven Su","photoUrl":"","userId":"12872522105664994411"}},"outputId":"968a8b83-e06d-45d6-8117-40bdac6937f4"},"source":["# PREPROCESSING DATA\n","tweets = []\n","data = list(categorized_tweets[\"response\"])\n","print(data[0])\n","for d in data:\n","    tweets.append(preprocess_text(d))\n","\n","y = categorized_tweets[\"label\"]\n","y = np.array(list(map(lambda x: 1 if x==\"SARCASM\" else 0, y)))"],"execution_count":13,"outputs":[{"output_type":"stream","text":["@USER @USER @USER I don't get this .. obviously you do care or you would've moved right along .. instead you decided to care and troll her ..\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WfDgEWiVwjPc","executionInfo":{"status":"ok","timestamp":1606256234024,"user_tz":420,"elapsed":561,"user":{"displayName":"Steven Su","photoUrl":"","userId":"12872522105664994411"}},"outputId":"6659b75d-3447-497f-aa6a-e15622354022"},"source":["# TOKENIZING DATA\n","num_words = 20000\n","oov_token = '<UNK>'\n","pad_type = 'post'\n","trunc_type = 'post'\n","\n","tokenizer = Tokenizer(num_words=num_words, oov_token=oov_token)\n","tokenizer.fit_on_texts(tweets)\n","train_sequences = tokenizer.texts_to_sequences(tweets)\n","maxlen = max([len(x) for x in train_sequences])\n","tokenized_tweets = pad_sequences(train_sequences, padding=pad_type, truncating=trunc_type, maxlen=maxlen)\n","\n","# tokenized example\n","print(tweets[9])\n","print(tokenized_tweets[9])"],"execution_count":15,"outputs":[{"output_type":"stream","text":["@USER @USER @USER responds to facts by tossing out frantic insults , then accuses others of being \" triggered by facts \" :rolling_on_the_floor_laughing: :face_with_tears_of_joy: :rolling_on_the_floor_laughing:\n","[   2    2    2 6083    4  443   50 6084   57 6085 1050  102 2510  234\n","    8   87 1347   50  443  131   17    3  158  148   31   15  117    8\n","   84  131   17    3  158  148    0    0    0    0    0    0    0    0\n","    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n","    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n","    0    0    0    0]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"P_EeynuOwwGH","executionInfo":{"status":"ok","timestamp":1606256244802,"user_tz":420,"elapsed":5972,"user":{"displayName":"Steven Su","photoUrl":"","userId":"12872522105664994411"}},"outputId":"d6de7b3a-9691-443f-f2d3-908b4150dcfc"},"source":["# PREPARE FOR TRAINING\n","tweets_with_len = [[tweet, y[i], len(tweet)] for i, tweet in enumerate(tokenized_tweets)]\n","random.shuffle(tweets_with_len)\n","tweets_with_len.sort(key=lambda x: x[2])\n","sorted_tweet_labels = [(tweet_lab[0], tweet_lab[1]) for tweet_lab in tweets_with_len]\n","processed_dataset = tf.data.Dataset.from_generator(lambda: sorted_tweet_labels, output_types=(tf.int32, tf.int32))\n","\n","BATCH_SIZE = 32\n","batched_dataset = processed_dataset.padded_batch(BATCH_SIZE, padded_shapes=((None, ), ()))\n","next(iter(batched_dataset))\n","TOTAL_BATCHES = math.ceil(len(sorted_tweet_labels) / BATCH_SIZE)\n","batched_dataset.shuffle(TOTAL_BATCHES)"],"execution_count":16,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<ShuffleDataset shapes: ((None, None), (None,)), types: (tf.int32, tf.int32)>"]},"metadata":{"tags":[]},"execution_count":16}]},{"cell_type":"code","metadata":{"id":"h0xlU60Ow00M","executionInfo":{"status":"ok","timestamp":1606256250106,"user_tz":420,"elapsed":273,"user":{"displayName":"Steven Su","photoUrl":"","userId":"12872522105664994411"}}},"source":["# BUILD MODEL\n","# Model hyperparameters\n","VOCAB_LENGTH = num_words\n","EMB_DIM = 200\n","CNN_FILTERS = 200\n","DNN_UNITS = 512\n","OUTPUT_CLASSES = 2\n","DROPOUT_RATE = 0.2\n","NB_EPOCHS = 10\n","\n","# Model object\n","text_model = TEXT_MODEL(vocabulary_size=VOCAB_LENGTH,\n","                        embedding_dimensions=EMB_DIM,\n","                        cnn_filters=CNN_FILTERS,\n","                        dnn_units=DNN_UNITS,\n","                        model_output_classes=OUTPUT_CLASSES,\n","                        dropout_rate=DROPOUT_RATE)"],"execution_count":17,"outputs":[]},{"cell_type":"code","metadata":{"id":"mpajhmkxw_H8","executionInfo":{"status":"ok","timestamp":1606256256295,"user_tz":420,"elapsed":323,"user":{"displayName":"Steven Su","photoUrl":"","userId":"12872522105664994411"}}},"source":["# Compile model\n","text_model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])"],"execution_count":18,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4GyI6dRWxCFn","executionInfo":{"status":"ok","timestamp":1606256342981,"user_tz":420,"elapsed":76520,"user":{"displayName":"Steven Su","photoUrl":"","userId":"12872522105664994411"}},"outputId":"1afcf887-8dee-49c2-e844-fc7cd1e7b458"},"source":["# Fit model\n","text_model.fit(batched_dataset, epochs=NB_EPOCHS)"],"execution_count":19,"outputs":[{"output_type":"stream","text":["Epoch 1/10\n","157/157 [==============================] - 7s 44ms/step - loss: 0.5894 - accuracy: 0.6682\n","Epoch 2/10\n","157/157 [==============================] - 7s 43ms/step - loss: 0.2683 - accuracy: 0.8884\n","Epoch 3/10\n","157/157 [==============================] - 7s 43ms/step - loss: 0.0489 - accuracy: 0.9836\n","Epoch 4/10\n","157/157 [==============================] - 7s 43ms/step - loss: 0.0048 - accuracy: 0.9992\n","Epoch 5/10\n","157/157 [==============================] - 7s 43ms/step - loss: 0.0033 - accuracy: 0.9996\n","Epoch 6/10\n","157/157 [==============================] - 7s 43ms/step - loss: 0.0019 - accuracy: 0.9998\n","Epoch 7/10\n","157/157 [==============================] - 7s 43ms/step - loss: 0.0021 - accuracy: 0.9998\n","Epoch 8/10\n","157/157 [==============================] - 7s 43ms/step - loss: 0.0012 - accuracy: 0.9998\n","Epoch 9/10\n","157/157 [==============================] - 7s 44ms/step - loss: 0.0024 - accuracy: 0.9998\n","Epoch 10/10\n","157/157 [==============================] - 7s 43ms/step - loss: 7.8772e-04 - accuracy: 0.9998\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<tensorflow.python.keras.callbacks.History at 0x7f6e2d826eb8>"]},"metadata":{"tags":[]},"execution_count":19}]},{"cell_type":"code","metadata":{"id":"fDPAC-QqlQih","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1606256371912,"user_tz":420,"elapsed":3556,"user":{"displayName":"Steven Su","photoUrl":"","userId":"12872522105664994411"}},"outputId":"dbcba9ad-86a5-4c9a-d6ac-f2df1e6a30f1"},"source":["\n","# Predict using model\n","uncat_tweets = pd.read_json('./data/test.jsonl', lines = True)\n","un_tweets = []\n","uncat_data = list(uncat_tweets[\"response\"])\n","\n","for d in uncat_data:\n","    un_tweets.append(preprocess_text(d))\n","\n","test_sequences = tokenizer.texts_to_sequences(un_tweets)\n","tokenized_un_tweets = pad_sequences(test_sequences, padding=pad_type, truncating=trunc_type, maxlen=maxlen)\n","\n","processed_dataset = tf.data.Dataset.from_generator(lambda:tokenized_un_tweets, output_types=tf.int32)\n","batched_dataset = processed_dataset.padded_batch(BATCH_SIZE, padded_shapes=(None, ))\n","\n","predictions = text_model.predict(batched_dataset)\n","\n","with open('answer.txt', 'w') as f:\n","    c = 1\n","    s_c = 0\n","    ns_c = 0\n","    for p in predictions:\n","        if p >= .5:\n","            f.write(\"twitter_\" + str(c) + \",\" + \"SARCASM\\n\")\n","            c += 1\n","            s_c += 1\n","        else:\n","            f.write(\"twitter_\" + str(c) + \",\" + \"NOT_SARCASM\\n\")\n","            c += 1\n","            ns_c += 1\n","print(\"# sarcasm: \" + str(s_c))\n","print(\"# not sarcasm: \" + str(ns_c))"],"execution_count":20,"outputs":[{"output_type":"stream","text":["# sarcasm: 925\n","# not sarcasm: 875\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"s2TmLSa_vWFR","executionInfo":{"status":"ok","timestamp":1606256686497,"user_tz":420,"elapsed":5582,"user":{"displayName":"Steven Su","photoUrl":"","userId":"12872522105664994411"}},"outputId":"eb438518-c1cd-4e79-84eb-a4ad832a8e64"},"source":["!git pull\n"],"execution_count":21,"outputs":[{"output_type":"stream","text":["Already up to date.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"bwKOzQHpW9-M"},"source":[""],"execution_count":null,"outputs":[]}]}